{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Lab3-Answers.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKibCt-QzolP"
      },
      "source": [
        "# Big Data\n",
        "\n",
        "Welcome to the world of ethically dubious big data!! \n",
        "\n",
        "This data is from a company called SafeGraph and they pay mobile apps for your location data so that they can track people and sell it to retailers. Since we're students, we can get access to some of their data for COVID analysis but I want you to think  what someone malicious could do with all this information.\n",
        "\n",
        "In order to use their data, you need to sign up *(link below)*. Once you have accesss, you get 100s of GBs of data that have people's location. In order to save the memory of your computer, I have subsetted out all the data for UVA and Cville. \n",
        "\n",
        "\n",
        "For this lab, I'm going to walk you through how I would try and piece together some quick analysis.\n",
        "\n",
        "\n",
        "## My question: How has foot traffic changed at UVA in 2019 vs 2020?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jL5C_w7wzolQ"
      },
      "source": [
        "import pandas as pd \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-1Vco9szolU"
      },
      "source": [
        "urlPrefix= \"https://nodepro.hackcville.com/week3/lab3/\"\n",
        "uva2019 = pd.read_csv(urlPrefix+ \"uvaFull2019.csv\")\n",
        "cville2019 =pd.read_csv(urlPrefix + \"cvilleFull2019.csv\")\n",
        "\n",
        "\n",
        "uva2020 = pd.read_csv(urlPrefix + \"uvaFull2020.csv\")\n",
        "cville2019 =pd.read_csv(urlPrefix + \"cvilleFull2020.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18gV20k3zolW"
      },
      "source": [
        "## Task 0: Take a look at uva2019 and uva202\n",
        "\n",
        "- What's the format of most the columns?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SIZsavCzolX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_SXA6XHzola"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ux8ksyS9zold"
      },
      "source": [
        "## Task 1A : Prepare for Merge\n",
        "We want to be able to merge the data so we can compare the popularity by day between 2019 and 2020 very easily. Our goal is to have them be in 1 dataframe.\n",
        "\n",
        "To do this, let's start by cleaning the data. \n",
        "\n",
        "- In `uva2019`, create a column called `2019Pop` that has the same information as `popularity_by_day` \n",
        "- In `uva2020`, create a column called `2020Pop` that has the same information as `popularity_by_day` \n",
        "\n",
        "\n",
        "- Create a new variable called `sub19` that is `uva2019`, subsetted to these columns \\[\"safegraph_place_id\", \"location_name\", \"2019Pop\"\\]\n",
        "- Create a new variable called `sub20` that is `uva2020`, subsetted to these columns \\[\"safegraph_place_id\", \"location_name\", \"2019Pop\"\\]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odMtIEJIzold"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDl26hAzzolf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBOs5r7Czoli"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkq7PCFszolk"
      },
      "source": [
        "## Task 1B- Time to Merge\n",
        "We want to merge `sub19` and `sub20` and only keep the information that they have in common.\n",
        "\n",
        "Look at the second page of the cheatsheet below and determine the right merge operation. \n",
        "\n",
        "https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fdg198Jxzoll"
      },
      "source": [
        "uva = \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kmlcXdWzoln"
      },
      "source": [
        "## Task 2A - Getting Weekly Visitors\n",
        "\n",
        "We want to be able to sum the information in 2019Pop and 2020Pop to get a total weekly count. However, we have a problem !! \n",
        "\n",
        "Notice how the information looks like a dictionary but when we inspect it below it is actually a str. \n",
        "\n",
        "You're first goal should be to see if you can programatically sum up all the values of the example below. \n",
        "\n",
        "\n",
        "Hints:\n",
        "- We want to convert a str to a dictionary first.\n",
        "    - Try looking up `json.loads`\n",
        "- Then we want to sum all values in a dictionary\n",
        "    - Try google searching how to do that\n",
        "    \n",
        "You know your logic is correct if it gives you 119.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnWDzUCQzoln"
      },
      "source": [
        "example = uva[\"2019Pop\"][0]\n",
        "print(example)\n",
        "print(type(example))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E41E5zrmzolp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35S7FZ01zolr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Wo4OZkHzolu"
      },
      "source": [
        "## 2B - Make a function\n",
        "\n",
        "Using the logic that we  used above, complete the rest of this function so it would work under any case.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWHdcaK5zolu"
      },
      "source": [
        "def strToDictToSum(dictAsString):\n",
        "    \n",
        "  \n",
        "    return 1\n",
        "    #replace 1 with the correct value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X-FkEB_zoly"
      },
      "source": [
        "#check yourself should be 119\n",
        "    #note if you merged slightly differently or \n",
        "        #shuffled your dataset it might be diffrent. \n",
        "        #When in doubt, print example and add manualy to confirm  \n",
        "strToDictToSum(example)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEGp7Cnizol2"
      },
      "source": [
        "## 2C- Apply the function to all rows.\n",
        "Using the apply method, use `strToDictToSum` on all rows. \n",
        "\n",
        "Example of apply:\n",
        "Given a sample dataframe df as:\n",
        ">**a**\n",
        "\n",
        "> 1\n",
        "\n",
        "> 2\n",
        "\n",
        "> 3\n",
        "\n",
        "> 4\n",
        "\n",
        "\n",
        "and I want to make a column b that uses a function `addOne`  on `a`. I would do \n",
        "\n",
        "`df['b'] = df['a'].apply(addOne)`\n",
        "\n",
        "**Tasks** \n",
        "- Create a column `weeklyVistors2019` which sums all of `2019Pop`\n",
        "- Create a column `weeklyVistors2020` which sums all of `2020Pop`\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfN6Qddmzol2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i248oP69zol4"
      },
      "source": [
        "## Task 3  - Clean it up\n",
        "- Create a new column `location`\n",
        "- Have the `uva` dataframe only contain the following columns: \\[\"location\",\"weeklyVistors2019\",\"weeklyVistors2020\"\\]\n",
        "- Show UVA DF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f53gD8KIzol4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diDTCQs6zol6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}